{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os \n",
    "import csv\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import joblib \n",
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.neural_network import MLPRegressor as MLPReg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10748, 13)\n"
     ]
    }
   ],
   "source": [
    "# Main file to be loaded ...\n",
    "testFile='./data/testF.csv'\n",
    "df=pd.read_csv('./data/trainComb.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(dataframe):\n",
    "    #Split into X,y \n",
    "    #Scale them\n",
    "    df1=dataframe[['cp','lsp','swvl1','ro','sd','dis']]\n",
    "    X = df1.iloc[:,:5].values.astype(float)\n",
    "    y = df1.iloc[:,-1].values.astype(float)\n",
    "    X=np.reshape(X,(-1,5))\n",
    "    y=np.reshape(y,(-1,1))\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(X)\n",
    "    y = sc_y.fit_transform(y)\n",
    "    return(X,y,sc_X,sc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10748, 5)\n(10748, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training it on the file.\n",
    "X,y,sx,sy=preProcessing(df)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1461, 5)\n(1461, 1)\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "X_test,y_test,sxt,syt=preProcessing(pd.read_csv(testFile))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet=MLPReg(hidden_layer_sizes=(15,10,5,3,1), activation='logistic',solver='adam', alpha=0.001, batch_size=batchSize,learning_rate='adaptive', learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model=neuralNet.fit(X,y.ravel())\n",
    "modelParams=model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36.76518490508725\n"
     ]
    }
   ],
   "source": [
    "# Loss Generation. \n",
    "y_pred_test = sy.inverse_transform((model.predict(X_test)))\n",
    "loss=1/1461*(MSE(sy.inverse_transform(y_test),y_pred_test))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./model_files/Neural_Net.sav']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Storing the files \n",
    "joblib.dump(model,str('./model_files/Neural_Net')+'.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}